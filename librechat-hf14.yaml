# Configuration version (required)
version: 1.0.0

# Cache settings: Set to true to enable caching
cache: true

# Definition of custom endpoints
endpoints:
  custom:
    # NagaAI
    - name: "NagaAI"
      # For `apiKey` and `baseURL`, you can use environment variables that you define.
      # recommended environment variables:
      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.
      apiKey: "user_provided"
      baseURL: "https://api.naga.ac/v1"
      models:
        default: ["claude-2", "claude-instant", "code-llama-34b", "falcon-180b-chat", "gemini-pro", "gemini-pro-vision", "gpt-3.5-turbo", "gpt-3.5-turbo-0613", "gpt-3.5-turbo-1106", "gpt-4", "gpt-4-0613", "gpt-4-1106-preview", "gpt-4-vision-preview", "llama-2-13b-chat", "llama-2-70b-chat", "llama-2-7b-chat", "mistral-7b", "mixtral-8x7b"]
        fetch: true
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "NagaAI"
      iconURL: "https://cdn-icons-png.flaticon.com/128/5278/5278402.png"

    # Cerebras
    - name: "Cerebras"
      apiKey: "csk-f9w9h46j83e2vfrk6kwpnc566whjy46yrfemc4erwk5k3rd6"  # ให้ผู้ใช้ป้อน API Key
      baseURL: "https://api.cerebras.ai/v1"
      models:
        default: ["llama3.1-8b", "llama3.1-70b", "llama-3.3-70b"]
        fetch: false
      titleConvo: true
      titleModel: "llama3.1-8b"
      summarize: false
      summaryModel: "llama3.1-8b"
      forcePrompt: false  # ปิดการส่ง `prompt` เพื่อใช้ `messages` แทน
      modelDisplayLabel: "Cerebras AI"
      iconURL: "https://cdn-icons-png.flaticon.com/128/8131/8131880.png"
      addParams:
        temperature: 0
        max_tokens: 100
        top_p: 1
      dropParams:
        - stop
        - temperature
        - top_p

    # DeepSeek
    - name: "DeepSeek"
      apiKey: "sk-7e65e1e268d4468a84f6d7fd4c946339"
      baseURL: "https://api.deepseek.com/v1"
      models:
        default: ["deepseek-chat"]
        fetch: false
      titleConvo: true
      titleModel: "deepseek-chat"
      summarize: false
      summaryModel: "deepseek-chat"
      forcePrompt: false
      modelDisplayLabel: "DeepSeek AI"
      iconURL: "https://cdn-icons-png.flaticon.com/128/1998/1998810.png"
      addParams:
        stream: false
      dropParams:
        - stop
        - temperature
        - top_p

    # SambaNova
    - name: "SambaNova"
      apiKey: "e2edf66e-21e2-498b-9379-1eef9378c8f5"
      baseURL: "https://api.sambanova.ai/v1"
      models:
        default:
          - "Meta-Llama-3.1-405B-Instruct"
          - "Meta-Llama-3.1-70B-Instruct"
          - "Meta-Llama-3.1-8B-Instruct"
          - "Meta-Llama-3.2-1B-Instruct"
          - "Meta-Llama-3.2-3B-Instruct"
          - "Meta-Llama-3.3-70B-Instruct"
          - "Meta-Llama-Guard-3-8B"
          - "Qwen2.5-72B-Instruct"
          - "Qwen2.5-Coder-32B-Instruct"
          - "QwQ-32B-Preview"
          - "Llama-3.2-11B-Vision-Instruct"
          - "Llama-3.2-90B-Vision-Instruct"
          - "Qwen2-Audio-7B-Instruct"
        fetch: false
      titleConvo: true
      titleModel: "Meta-Llama-3.1-8B-Instruct"
      summarize: false
      summaryModel: "Meta-Llama-3.1-8B-Instruct"
      forcePrompt: false
      modelDisplayLabel: "SambaNova AI"
      iconURL: "https://cdn-icons-png.flaticon.com/128/12122/12122348.png"
      addParams:
        stream: true
      dropParams:
        - stop
        - temperature
        - top_p

    # AIEat Siam ai
    - name: "Siamai"
      apiKey: "dummy"
      baseURL: "https://api.aieat.or.th/v1"
      models:
        default: ["."]
        fetch: false
      titleConvo: true
      titleModel: "."
      summarize: false
      summaryModel: "."
      forcePrompt: true
      modelDisplayLabel: "AIEat"
      iconURL: "https://cdn-icons-png.flaticon.com/128/10598/10598728.png"
      addParams:
        max_tokens: 512
        temperature: 0.7
        top_p: 0.8
        top_k: 40
        stop:
          - "<|im_end|>"
          - "||"
          - "Assistant:"
          - "Human:"
      dropParams:
        - stop
        - temperature
        - top_p

    # OpenTyphoon.ai API
    - name: "OpenTyphoon"
      apiKey: "sk-BET4yZq8hG3uoUwo2ilOyMYEhoXk1Uel3Gz9v5VpGMk6Hio7"  # Replace with your actual API key
      baseURL: "https://api.opentyphoon.ai/v1/chat/completions"
      models:
        default:
          - "typhoon-instruct"
          - "typhoon-v1.5-instruct"
          - "typhoon-v1.5x-70b-instruct"
          - "typhoon-v2-8b-instruct"
          - "typhoon-v2-70b-instruct"
        fetch: false
      addParams:
        max_tokens: 512
        temperature: 0.6
        top_p: 0.95
        repetition_penalty: 1.05
        stream: false
      dropParams:
        - stop
        - metadata
        - store
      titleConvo: true
      modelDisplayLabel: "OpenTyphoon AI"
      iconURL: "https://cdn-icons-png.flaticon.com/128/8484/8484072.png"

    # Groq AI
    - name: "Groq"
      apiKey: "GROQ_API_KEY"  # Replace with your actual API key
      baseURL: "https://api.groq.com/openai/v1"
      models:
        default:
          - "llama-3.3-70b-versatile"
          - "llama-3.1-8b-instant"
          - "llama-guard-3-8b"
          - "llama3-70b-8192"
          - "llama3-8b-8192"
          - "mixtral-8x7b-32768"
        fetch: false
      titleConvo: true
      titleModel: "llama-3.3-70b-versatile"
      summarize: false
      summaryModel: "llama-3.3-70b-versatile"
      forcePrompt: false
      modelDisplayLabel: "Groq AI"
      iconURL: "https://cdn-icons-png.flaticon.com/128/888/888843.png"
      addParams:
        temperature: 0.7
        max_tokens: 512
        top_p: 0.9
      dropParams:
        - stop
        - temperature
        - top_p
        
    # Hugging Face Microsoft Phi-4 API
    - name: "Hugging Face"
      apiKey: "user_provided"
      baseURL: "https://api-inference.huggingface.co/v1"
      models:
        default:
          - "PowerInfer/SmallThinker-3B-Preview"
          - "impira/layoutlm-document-qa"
          - "mistralai/Mistral-Nemo-Instruct-2407"
          - "mistralai/Mixtral-8x7B-Instruct-v0.1"
          - "NousResearch/Hermes-3-Llama-3.1-8B"
          - "CodeLlama/CodeLlama-34B-Instruct-hf"
          - "meta-llama/Llama-3.1-8B-Instruct"
          - "meta-llama/Llama-3.2-1B-Instruct"
          - "meta-llama/Llama-3.2-3B-Instruct"
          - "meta-llama/Llama-3.3-70B-Instruct"
          - "tiiuae/falcon-7b-instruct"
          - "Qwen/Qwen2.5-Coder-32B-Instruct"
          - "Qwen/Qwen2.5-72B-Instruct"
          - "Qwen/QwQ-32B-Preview"
          - "microsoft/Phi-3.5-mini-instruct"
          - "01-ai/Yi-1.5-34B-Chat"
          - "HuggingFaceH4/starchat2-15b-v0.1"
        fetch: false
      titleConvo: true
      titleModel: "NousResearch/Hermes-3-Llama-3.1-8B"
      summarize: false
      summaryModel: "NousResearch/Hermes-3-Llama-3.1-8B"
      forcePrompt: false
      modelDisplayLabel: "Hugging Face "
      iconURL: "https://huggingface.co/favicon.ico"
      addParams:
        max_tokens: 500
        stream: true
      dropParams:
        - stop
        - temperature
        - top_p

    # OpenRouter.ai
    # Model list: https://openrouter.ai/models
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/openrouter.py
    - name: "OpenRouter"
      apiKey: "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"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "openrouter/auto",
          "---FREE---",
          "google/gemma-2-9b-it:free",
          "gryphe/mythomax-l2-13b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "liquid/lfm-40b:free",
          "meta-llama/llama-3-8b-instruct:free",
          "meta-llama/llama-3.1-405b-instruct:free",
          "meta-llama/llama-3.1-70b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "meta-llama/llama-3.2-11b-vision-instruct:free",
          "meta-llama/llama-3.2-1b-instruct:free",
          "meta-llama/llama-3.2-3b-instruct:free",
          "meta-llama/llama-3.2-90b-vision-instruct:free",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "mistralai/mistral-7b-instruct:free",
          "nousresearch/hermes-3-llama-3.1-405b:free",
          "openchat/openchat-7b:free",
          "qwen/qwen-2-7b-instruct:free",
          "undi95/toppy-m-7b:free",
          "---NITRO---",
          "gryphe/mythomax-l2-13b:nitro",
          "meta-llama/llama-3-70b-instruct:nitro",
          "meta-llama/llama-3-8b-instruct:nitro",
          "meta-llama/llama-3.1-405b-instruct:nitro",
          "meta-llama/llama-3.1-70b-instruct:nitro",
          "mistralai/mistral-7b-instruct:nitro",
          "mistralai/mixtral-8x7b-instruct:nitro",
          "undi95/toppy-m-7b:nitro",
          "---BETA---",
          "anthropic/claude-2.0:beta",
          "anthropic/claude-2.1:beta",
          "anthropic/claude-2:beta",
          "anthropic/claude-3-5-haiku-20241022:beta",
          "anthropic/claude-3-5-haiku:beta",
          "anthropic/claude-3-haiku:beta",
          "anthropic/claude-3-opus:beta",
          "anthropic/claude-3-sonnet:beta",
          "anthropic/claude-3.5-sonnet-20240620:beta",
          "anthropic/claude-3.5-sonnet:beta",
          "---EXTENDED---",
          "gryphe/mythomax-l2-13b:extended",
          "meta-llama/llama-3-8b-instruct:extended",
          "neversleep/llama-3-lumimaid-8b:extended",
          "openai/gpt-4o:extended",
          "undi95/remm-slerp-l2-13b:extended",
          "---AI21---",
          "ai21/jamba-1-5-large",
          "ai21/jamba-1-5-mini",
          "ai21/jamba-instruct",
          "---ANTHROPIC---",
          "anthropic/claude-2",
          "anthropic/claude-2.0",
          "anthropic/claude-2.1",
          "anthropic/claude-3-5-haiku",
          "anthropic/claude-3-5-haiku-20241022",
          "anthropic/claude-3-haiku",
          "anthropic/claude-3-opus",
          "anthropic/claude-3-sonnet",
          "anthropic/claude-3.5-sonnet",
          "anthropic/claude-3.5-sonnet-20240620",
          "---COHERE---",
          "cohere/command",
          "cohere/command-r",
          "cohere/command-r-03-2024",
          "cohere/command-r-08-2024",
          "cohere/command-r-plus",
          "cohere/command-r-plus-04-2024",
          "cohere/command-r-plus-08-2024",
          "---GOOGLE---",
          "google/gemini-exp-1114",
          "google/gemini-flash-1.5",
          "google/gemini-flash-1.5-8b",
          "google/gemini-flash-1.5-8b-exp",
          "google/gemini-flash-1.5-exp",
          "google/gemini-pro",
          "google/gemini-pro-1.5",
          "google/gemini-pro-1.5-exp",
          "google/gemini-pro-vision",
          "google/gemma-2-27b-it",
          "google/gemma-2-9b-it",
          "google/palm-2-chat-bison",
          "google/palm-2-chat-bison-32k",
          "google/palm-2-codechat-bison",
          "google/palm-2-codechat-bison-32k",
          "---META-LLAMA---",
          "meta-llama/llama-2-13b-chat",
          "meta-llama/llama-3-70b-instruct",
          "meta-llama/llama-3-8b-instruct",
          "meta-llama/llama-3.1-405b",
          "meta-llama/llama-3.1-405b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "meta-llama/llama-3.1-8b-instruct",
          "meta-llama/llama-3.2-11b-vision-instruct",
          "meta-llama/llama-3.2-1b-instruct",
          "meta-llama/llama-3.2-3b-instruct",
          "meta-llama/llama-3.2-90b-vision-instruct",
          "meta-llama/llama-guard-2-8b",
          "---MICROSOFT---",
          "microsoft/phi-3-medium-128k-instruct",
          "microsoft/phi-3-mini-128k-instruct",
          "microsoft/phi-3.5-mini-128k-instruct",
          "microsoft/wizardlm-2-7b",
          "microsoft/wizardlm-2-8x22b",
          "---MISTRALAI---",
          "mistralai/codestral-mamba",
          "mistralai/ministral-3b",
          "mistralai/ministral-8b",
          "mistralai/mistral-7b-instruct",
          "mistralai/mistral-7b-instruct-v0.1",
          "mistralai/mistral-7b-instruct-v0.2",
          "mistralai/mistral-7b-instruct-v0.3",
          "mistralai/mistral-large",
          "mistralai/mistral-large-2407",
          "mistralai/mistral-large-2411",
          "mistralai/mistral-medium",
          "mistralai/mistral-nemo",
          "mistralai/mistral-small",
          "mistralai/mistral-tiny",
          "mistralai/mixtral-8x22b-instruct",
          "mistralai/mixtral-8x7b",
          "mistralai/mixtral-8x7b-instruct",
          "mistralai/pixtral-12b",
          "mistralai/pixtral-large-2411",
          "---NEVERSLEEP---",
          "neversleep/llama-3-lumimaid-70b",
          "neversleep/llama-3-lumimaid-8b",
          "neversleep/llama-3.1-lumimaid-70b",
          "neversleep/llama-3.1-lumimaid-8b",
          "neversleep/noromaid-20b",
          "---NOUSRESEARCH---",
          "nousresearch/hermes-2-pro-llama-3-8b",
          "nousresearch/hermes-3-llama-3.1-405b",
          "nousresearch/hermes-3-llama-3.1-70b",
          "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
          "nousresearch/nous-hermes-llama2-13b",
          "---OPENAI---",
          "openai/chatgpt-4o-latest",
          "openai/gpt-3.5-turbo",
          "openai/gpt-3.5-turbo-0125",
          "openai/gpt-3.5-turbo-0613",
          "openai/gpt-3.5-turbo-1106",
          "openai/gpt-3.5-turbo-16k",
          "openai/gpt-3.5-turbo-instruct",
          "openai/gpt-4",
          "openai/gpt-4-0314",
          "openai/gpt-4-1106-preview",
          "openai/gpt-4-32k",
          "openai/gpt-4-32k-0314",
          "openai/gpt-4-turbo",
          "openai/gpt-4-turbo-preview",
          "openai/gpt-4-vision-preview",
          "openai/gpt-4o",
          "openai/gpt-4o-2024-05-13",
          "openai/gpt-4o-2024-08-06",
          "openai/gpt-4o-2024-11-20",
          "openai/gpt-4o-mini",
          "openai/gpt-4o-mini-2024-07-18",
          "openai/o1-mini",
          "openai/o1-mini-2024-09-12",
          "openai/o1-preview",
          "openai/o1-preview-2024-09-12",
          "---PERPLEXITY---",
          "perplexity/llama-3-sonar-large-32k-chat",
          "perplexity/llama-3-sonar-large-32k-online",
          "perplexity/llama-3-sonar-small-32k-chat",
          "perplexity/llama-3.1-sonar-huge-128k-online",
          "perplexity/llama-3.1-sonar-large-128k-chat",
          "perplexity/llama-3.1-sonar-large-128k-online",
          "perplexity/llama-3.1-sonar-small-128k-chat",
          "perplexity/llama-3.1-sonar-small-128k-online",
          "---QWEN---",
          "qwen/qwen-2-72b-instruct",
          "qwen/qwen-2-7b-instruct",
          "qwen/qwen-2-vl-72b-instruct",
          "qwen/qwen-2-vl-7b-instruct",
          "qwen/qwen-2.5-72b-instruct",
          "qwen/qwen-2.5-7b-instruct",
          "qwen/qwen-2.5-coder-32b-instruct",
          "---OTHERS---",
          "01-ai/yi-large",
          "alpindale/goliath-120b",
          "alpindale/magnum-72b",
          "anthracite-org/magnum-v4-72b",
          "cognitivecomputations/dolphin-mixtral-8x22b",
          "cognitivecomputations/dolphin-mixtral-8x7b",
          "databricks/dbrx-instruct",
          "deepseek/deepseek-chat",
          "eva-unit-01/eva-qwen-2.5-32b",
          "gryphe/mythomax-l2-13b",
          "infermatic/mn-inferor-12b",
          "inflection/inflection-3-pi",
          "inflection/inflection-3-productivity",
          "jondurbin/airoboros-l2-70b",
          "liquid/lfm-40b",
          "lizpreciatior/lzlv-70b-fp16-hf",
          "mancer/weaver",
          "nvidia/llama-3.1-nemotron-70b-instruct",
          "openchat/openchat-7b",
          "pygmalionai/mythalion-13b",
          "raifle/sorcererlm-8x22b",
          "sao10k/l3-euryale-70b",
          "sao10k/l3.1-euryale-70b",
          "sophosympatheia/midnight-rose-70b",
          "teknium/openhermes-2.5-mistral-7b",
          "thedrummer/rocinante-12b",
          "thedrummer/unslopnemo-12b",
          "undi95/remm-slerp-l2-13b",
          "undi95/toppy-m-7b",
          "x-ai/grok-beta",
          "x-ai/grok-vision-beta",
          "xwin-lm/xwin-lm-70b"
          ]
        fetch: false
      dropParams: ["stop"]
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    # Mistral AI API
    # Model list: https://docs.mistral.ai/getting-started/models/
    - name: "Mistral"
      apiKey: "HXadBjtsE7YJUfbq6zn56MZ9hiEuSNPs"
      baseURL: "https://api.mistral.ai/v1"
      models: 
        default: [
          "mistral-large-latest",
          "pixtral-large-latest",
          "ministral-3b-latest",
          "ministral-8b-latest",
          "mistral-small-latest",
          "codestral-latest",
          "pixtral-12b-2409",
          "open-mistral-nemo",
          "open-codestral-mamba",
          "open-mistral-7b",
          "open-mixtral-8x7b",
          "open-mixtral-8x22b"
          ]
        fetch: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "mistral-tiny"
      summarize: false
      summaryModel: "mistral-tiny"
      forcePrompt: false
      modelDisplayLabel: "Mistral"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # cohere
    # Model list: https://dashboard.cohere.com/playground/chat
    - name: "cohere"
      apiKey: "gV3sKYBJKzcCKdk1iDO82SGb7u6lMV18I7FyY7r5"
      baseURL: "https://api.cohere.ai/v1"
      models:
        default: [
          "c4ai-aya-23-35b",
          "c4ai-aya-23-8b",
          "command",
          "command-light",
          "command-light-nightly",
          "command-nightly",
          "command-r",
          "command-r-plus",
          ]
        fetch: false
      modelDisplayLabel: "cohere"
      titleModel: "command"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty", "temperature", "top_p"]

# See the Custom Configuration Guide for more information:
# https://docs.librechat.ai/install/configuration/custom_config.html
